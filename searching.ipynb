{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import math\n",
    "from pymystem3 import Mystem\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import urllib\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docs(path):\n",
    "    df = pd.read_csv(path, skiprows=0)\n",
    "    ids = df['id'].to_numpy()\n",
    "    docs = df['text'].to_numpy()\n",
    "    return ids, docs\n",
    "\n",
    "ids, docs = read_docs('texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'myandex'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYANDEX = 'myandex'\n",
    "settings = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'content': {\n",
    "                'type': 'text'\n",
    "             }\n",
    "         }\n",
    "    },\n",
    "    'settings': {\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                'white_lover': {\n",
    "                    'tokenizer': 'letter',\n",
    "                    'filter': [\n",
    "                        'lowercase', \n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'timeout': 360, 'maxsize': 25}])\n",
    "es.indices.delete(MYANDEX)\n",
    "es.indices.create(index=MYANDEX, body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }\n",
    "\n",
    "def create_index(all_docs, index):\n",
    "    def next_document():\n",
    "        for i, doc in tqdm_notebook(list(zip(ids, all_docs))):\n",
    "            if doc is not None:\n",
    "                yield create_es_action(index, int(i), {'content': str(doc)})\n",
    "    \n",
    "    for ok, result in parallel_bulk(es, next_document(), queue_size=4, thread_count=4, chunk_size=1000):\n",
    "        if not ok:\n",
    "            print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23db7c33962544f6999081dd14cca8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=199368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_index(docs, MYANDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '332329', 'score': 6.322534},\n",
       " {'id': '677707', 'score': 6.3214607},\n",
       " {'id': '1322832', 'score': 6.2616105},\n",
       " {'id': '308211', 'score': 6.216829},\n",
       " {'id': '563489', 'score': 6.2017894},\n",
       " {'id': '633870', 'score': 6.200276},\n",
       " {'id': '967868', 'score': 6.1842537},\n",
       " {'id': '720665', 'score': 6.136043},\n",
       " {'id': '1091727', 'score': 6.1353703},\n",
       " {'id': '528882', 'score': 6.1119347},\n",
       " {'id': '271267', 'score': 6.1099944},\n",
       " {'id': '1196434', 'score': 6.1097217},\n",
       " {'id': '1488521', 'score': 6.104635},\n",
       " {'id': '1308244', 'score': 6.0981293},\n",
       " {'id': '795213', 'score': 6.0903134},\n",
       " {'id': '1002619', 'score': 6.0827484},\n",
       " {'id': '1203731', 'score': 6.077414},\n",
       " {'id': '924753', 'score': 6.0756383},\n",
       " {'id': '64833', 'score': 6.0557446},\n",
       " {'id': '9098', 'score': 6.0557446}]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query, index, *args, K=20):\n",
    "    res = es.search(index=index, body=query, size=K)[\"hits\"]\n",
    "    pretty_res = []\n",
    "    for hit in res['hits']:\n",
    "        pretty_res.append({'id': hit[\"_id\"],\n",
    "                           'score': hit[\"_score\"]})\n",
    "    return pretty_res\n",
    "\n",
    "def search_and_print(query, index, *args):\n",
    "    pretty_print_result(es.search(index=index, body=query, size=20), args)\n",
    "    # note that size set to 20 just because default value is 10 and we know that we have 12 docs and 10 < 12 < 20\n",
    "                        \n",
    "def pretty_print_result(search_result, fields=[]):\n",
    "    # fields is a list of fields names which we want to be printed\n",
    "    res = search_result['hits']\n",
    "    print(f'Total documents: {res[\"total\"][\"value\"]}')\n",
    "    for hit in res['hits']:\n",
    "        print(f'Doc {hit[\"_id\"]}, score is {hit[\"_score\"]}')\n",
    "        for field in fields:\n",
    "            print(f'{field}: {hit[\"_source\"][field]}')\n",
    "                  \n",
    "def get_doc_by_id(doc_id):\n",
    "    return es.get(index=MYANDEX, id=doc_id)['_source']\n",
    "\n",
    "def build_query(query):\n",
    "    return {\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {\n",
    "                        'match': {\n",
    "                            'content': query\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "search(build_query('Андрей'), MYANDEX, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_index_size(index): \n",
    "    print(f\"{(es.indices.stats(index)['_all']['primaries']['store']['size_in_bytes'] / 2 ** 30):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.17 GB\n"
     ]
    }
   ],
   "source": [
    "print_index_size(MYANDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def lemmatize_doc(doc):\n",
    "    return ''.join(m.lemmatize(str(doc)))\n",
    "    \n",
    "def lemmatize_collection(docs):\n",
    "    result = []\n",
    "    for doc in tqdm_notebook(docs):\n",
    "        result.append(lemmatize_doc(doc))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lemmas(lemmas):\n",
    "    with open('lemmas.pickle', 'wb') as f:\n",
    "        pickle.dump(lemmatized_docs, f)\n",
    "\n",
    "def load_lemmas():\n",
    "    with open('lemmas.pickle', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized_docs = lemmatize_collection(docs)\n",
    "lemmatized_docs = load_lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(s):\n",
    "    s = base64.b64decode(s)\n",
    "    s = codecs.decode(s, 'cp1251', errors='ignore')\n",
    "    return s\n",
    "\n",
    "def get_quieries(relevance):\n",
    "    queries = {}\n",
    "    with open('web2008_adhoc.xml','r', encoding=\"cp1251\") as src:\n",
    "        raw_xml = src.read()\n",
    "        soup = BeautifulSoup(raw_xml)\n",
    "        for task in soup.find_all('task'):\n",
    "            if task['id'] in relevance:\n",
    "                queries[task['id']] = task.querytext.string\n",
    "    return queries\n",
    "\n",
    "def get_relevance():\n",
    "    relevance = {}\n",
    "    with open('or_relevant-minus_table.xml','r', encoding=\"cp1251\") as src:\n",
    "        raw_xml = src.read()\n",
    "        soup = BeautifulSoup(raw_xml)\n",
    "        \n",
    "        for task in soup.find_all('task'):\n",
    "            documents = task.find_all('document') \n",
    "            vital = set()\n",
    "            for doc in documents:\n",
    "                if doc['relevance'] == 'vital':\n",
    "                    vital.add(doc['id'])\n",
    "            if vital:\n",
    "                relevance[task['id']] = vital\n",
    "    return relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 495\n"
     ]
    }
   ],
   "source": [
    "relevance = get_relevance()\n",
    "queries = get_quieries(relevance)\n",
    "print(len(relevance), len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546507b57f004fee8a883d02c86bd01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=495), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p@20 0.2682828282828283\n",
      "r@20 0.18055493176592302\n",
      "R-precision 0.1529419202313428\n",
      "Average MAP@20 0.3051976683724968\n"
     ]
    }
   ],
   "source": [
    "K = 20\n",
    "\n",
    "def get_relevant_for_k(res, relevant, k):\n",
    "    return sum([1 if res['id'] in relevant else 0 for res in res[:k]])        \n",
    "\n",
    "def analyze_results(index, lemmatize_query=False):\n",
    "    Q = len(queries)\n",
    "    qpK, qrK, qR_average, qmapK = 0, 0, 0, 0\n",
    "    qR = []\n",
    "    for task, q in tqdm_notebook(queries.items()):\n",
    "        if lemmatize_query:\n",
    "            q = lemmatize_doc(q)\n",
    "        results = search(build_query(q), index, K)\n",
    "        cur_relevant = len(relevance[task])\n",
    "        qpK += get_relevant_for_k(results, relevance[task], K) / K \n",
    "        qrK += get_relevant_for_k(results, relevance[task], K) / cur_relevant\n",
    "        qR.append(get_relevant_for_k(results, relevance[task], cur_relevant) / cur_relevant)\n",
    "        qR_average += qR[-1]\n",
    "        mapK = 0\n",
    "        for k in range(1, K + 1):\n",
    "            mapK += get_relevant_for_k(results, relevance[task], k) / k\n",
    "        mapK /= K\n",
    "        qmapK += mapK\n",
    "    print(f\"p@20 {qpK / Q}\")\n",
    "    print(f\"r@20 {qrK / Q}\")\n",
    "    print(f\"R-precision {qR_average / Q}\")\n",
    "    print(f\"Average MAP@20 {qmapK / Q}\")\n",
    "    return np.array(qR)\n",
    "        \n",
    "qR_pure = analyze_results(MYANDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1b3551809b49d3882589928e63c89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=199368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14 GB\n"
     ]
    }
   ],
   "source": [
    "MYANDEX_LEMMAS = 'myandex_lemmas'\n",
    "es.indices.delete(MYANDEX_LEMMAS)\n",
    "es.indices.create(index=MYANDEX_LEMMAS, body=settings)\n",
    "create_index(lemmatized_docs, MYANDEX_LEMMAS)\n",
    "print_index_size(MYANDEX_LEMMAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dc8e64f3da4ecba7d5646936543698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=495), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p@20 0.401010101010101\n",
      "r@20 0.26760448426425604\n",
      "R-precision 0.22521276526825904\n",
      "Average MAP@20 0.45474138485518534\n"
     ]
    }
   ],
   "source": [
    "qR_lemmas = analyze_results(MYANDEX_LEMMAS, lemmatize_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1537e7d24f51400c8ed31f51a185a61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=199368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92 GB\n"
     ]
    }
   ],
   "source": [
    "MYANDEX_TITLE = 'myandex_title'\n",
    "settings = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'title': {\n",
    "                'type': 'text'\n",
    "             },            \n",
    "            'content': {\n",
    "                'type': 'text'\n",
    "             }\n",
    "         }\n",
    "    },\n",
    "    'settings': {\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                'white_lover': {\n",
    "                    'tokenizer': 'letter',\n",
    "                    'filter': [\n",
    "                        'lowercase', \n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.delete(MYANDEX_TITLE)\n",
    "es.indices.create(index=MYANDEX_TITLE, body=settings)\n",
    "\n",
    "def create_index_titled(all_docs, index):\n",
    "    def next_document():\n",
    "        for i, doc in tqdm_notebook(list(zip(ids, all_docs))):\n",
    "            if doc is not None:\n",
    "                doc = str(doc).split('\\n', 1)\n",
    "                if len(doc) == 2:\n",
    "                    title, body = doc\n",
    "                    yield create_es_action(index, int(i), {'content': body, 'title': title})\n",
    "    \n",
    "    for ok, result in parallel_bulk(es, next_document(), queue_size=4, thread_count=4, chunk_size=1000):\n",
    "        if not ok:\n",
    "            print(result)\n",
    "            \n",
    "\n",
    "create_index_titled(lemmatized_docs, MYANDEX_TITLE)\n",
    "print_index_size(MYANDEX_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8090d6c1a5d4ff484f274f2d27d0760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=495), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p@20 0.40959595959595946\n",
      "r@20 0.26869876829820327\n",
      "R-precision 0.22932912345173131\n",
      "Average MAP@20 0.46620991140582557\n"
     ]
    }
   ],
   "source": [
    "def build_query(query):\n",
    "    return {\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {\n",
    "                        'match': {\n",
    "                            'title': {\n",
    "                                'query': query,\n",
    "                                'boost': 0.15\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'match': {\n",
    "                            'content': query\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "qR_titles = analyze_results(MYANDEX, lemmatize_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_diff(k=10):\n",
    "    diffs = np.abs(qR_lemmas - qR_pure)\n",
    "#     print(diffs)\n",
    "    ascending = np.argsort(diffs)\n",
    "#     print(ascending)\n",
    "    for i in range(k):\n",
    "        idx = ascending[-i - 1]\n",
    "        q = list(queries.values())[idx]\n",
    "        print(f'{q} {lemmatize_doc(q)} lemmas {qR_lemmas[idx]} vs pure {qR_pure[idx]}')\n",
    "#         search_and_print(build_query(lemmatize_doc(q)), MYANDEX_LEMMAS, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "УРАЛЬСКАЯ ПЛИТКА уральский плитка\n",
      " lemmas 1.0 vs pure 0.0\n",
      "аугментин - состав аугментина - состав\n",
      " lemmas 1.0 vs pure 0.0\n",
      "контакт контакт\n",
      " lemmas 1.0 vs pure 0.0\n",
      "гда находится занзибар гда находиться занзибар\n",
      " lemmas 0.6 vs pure 0.0\n",
      "уральские авиалинии уральский авиалиния\n",
      " lemmas 0.5862068965517241 vs pure 0.0\n",
      "иониты в катализе ионит в катализ\n",
      " lemmas 0.5714285714285714 vs pure 0.0\n",
      "допуски и посадки допуск и посадка\n",
      " lemmas 0.5652173913043478 vs pure 0.0\n",
      "МАГАЗИН СУПИНАТОРЫ магазин супинатор\n",
      " lemmas 0.5625 vs pure 0.0\n",
      "византийские источники о руси византийский источник о русь\n",
      " lemmas 0.5384615384615384 vs pure 0.0\n",
      "карта турции карта турция\n",
      " lemmas 0.5 vs pure 0.0\n"
     ]
    }
   ],
   "source": [
    "max_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
